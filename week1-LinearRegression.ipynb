{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Cost Function\n",
    "\n",
    "**Hypothesis** $h_\\theta = \\theta_0 + \\theta_1x$\n",
    "\n",
    "**Parameter** $\\theta_1, \\theta_0$\n",
    "\n",
    "**Cost Function** $J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=m1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "**Goal** : find $\\theta_0, \\theta_1$ to minimize $J(\\theta_0,\\theta_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Gradient decent\n",
    "Have some function $(J\\theta_0,\\theta_1)$\n",
    "\n",
    "Want $min_{\\theta_0,\\theta_1}J(\\theta_0,\\theta_1)$\n",
    "\n",
    "#### Outline\n",
    "* Start with some $\\theta_0,\\theta_1$\n",
    "* Keep changing $\\theta_0,\\theta_1$ to reduce $J(\\theta_0,\\theta_1)$ until we (hopefully) end up w a minium\n",
    "\n",
    "#### Algorithm\n",
    "> repeate until convergence $\\{\n",
    "\\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)\\} $\n",
    "\n",
    ">$\\alpha : learning rate $\n",
    "\n",
    "**Simultaneous update**\n",
    "\n",
    ">$$ {\\color{red}{temp0}} := \\theta_0 - \\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1) \\\\\n",
    "{\\color{red}{temp1}} := \\theta_1 - \\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1) \\\\\n",
    "\\\\\n",
    "{\\color{red}{\\theta_0}} := temp0\\\\\n",
    "{\\color{red}{\\theta_1}} := temp1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intuition\n",
    "We update the $\\theta_1$ and look at the slope of the tangent line to the graph between $\\theta_1$ and $J(\\theta_1)$\n",
    "\n",
    "if the sample point isn't the local minimum, the partial dervative will be non-zero -> the updated $\\theta$ will be different from $\\theta$\n",
    "\n",
    "* If $\\alpha$ is too small, the gradient descent can be slow.\n",
    "* If $\\alpha$ is too large, the gradient descent can overshoot the minimum.\n",
    "\n",
    "Gradient descent can converge to a local minimum, even with the learning rate $\\alpha$ fixed. Since as we approach a local minimum, gradient descent will automatically take smaller steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Find partial derivative\n",
    "\n",
    "$$\n",
    "\\alpha\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1) \n",
    "= \\alpha\\frac{\\partial}{\\partial\\theta_0}\\frac{1}{2m}\n",
    "\\sum_{i=m1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "We have the partial derivative to be:\n",
    "\n",
    "$$ j = 0 : \\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1) = \\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)}) $$\n",
    "\n",
    "$$ j = 1 : \\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1) = \\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)} $$\n",
    "\n",
    "This lead to a more simplified gradient descent algorithm:\n",
    "\n",
    "> **repeat until convergence** $ \\{ \\\\\n",
    "\\color{red}{\\theta_0} := \\theta_0 - \\alpha\\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)}) \\\\\n",
    "\\color{red}{\\theta_1} := \\theta_1 - \\alpha\\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}\\\\\n",
    "\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Batch\" Gradient Descent\n",
    "\n",
    "$\\color{red}{Batch}$ : each step of gradient descent uses all the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [1 3 -1]\n",
    "B = [2; 2; 4]\n",
    "C = mtimes(A,B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
